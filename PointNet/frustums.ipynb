{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frustum Pointnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import pickle\n",
    "\n",
    "EQUAL_ASPECT_RATIO_LAYOUT = dict(\n",
    "    margin={\n",
    "        'l': 0,\n",
    "        'r': 0,\n",
    "        'b': 0,\n",
    "        't': 0\n",
    "    }, scene=dict(\n",
    "    aspectmode='data'\n",
    "))\n",
    "\n",
    "\n",
    "def color(x, cmap='Reds'):\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    x = (x - np.min(x)) / np.max(x)\n",
    "    \n",
    "    return cmap(x)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='http://stanford.edu/~rqi/frustum-pointnets/images/teaser.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given RGB-D data, we first generate 2D object region proposals in the RGB image using a CNN. Each 2D region is then extruded to a 3D viewing frustum in which we get a point cloud from depth data. Finally, our frustum PointNet predicts a (oriented and amodal) 3D bounding box for the object from the points in frustum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получение frustum-примеров из сырых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(url='http://www.cvlibs.net/datasets/kitti/images/passat_sensors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='http://www.cvlibs.net/datasets/kitti/images/setup_top_view.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('projection_example.npy', 'rb') as f:\n",
    "    data_example = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample image, point cloud data, calibration and transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = data_example['lidar_xyz']\n",
    "intensity = data_example['intensity']\n",
    "car_to_cam = data_example['car_to_cam']\n",
    "car_to_lidar = data_example['car_to_lidar']\n",
    "intrinsic = data_example['intrinsics']\n",
    "image = data_example['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_to_cam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(xyz[:, 0], xyz[:, 1], s=0.1)\n",
    "plt.xlim(0, 60)\n",
    "plt.ylim(-35, 35);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=EQUAL_ASPECT_RATIO_LAYOUT)\n",
    "fig.add_scatter3d(**{\n",
    "    'x': xyz[:,0],\n",
    "    'y': xyz[:,1],\n",
    "    'z': xyz[:,2],\n",
    "    'mode': 'markers',\n",
    "    'marker': {\n",
    "        'size': 1,\n",
    "        'color': color(intensity, 'tab20')\n",
    "    }\n",
    "})\n",
    "\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a frustum (e.g., a bounding box predicted by 2D detection pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = np.array(((350, 750), (460, 810)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_vertices(bbox):\n",
    "    return np.array([bbox[0], [bbox[0, 0], bbox[1, 1]], bbox[1], [bbox[1, 0], bbox[0, 1]], bbox[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = bbox_to_vertices(bbox)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(image)\n",
    "plt.plot(vertices[:, 1], vertices[:, 0], c='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что хотим сделать? \n",
    "\n",
    "* Спроецируем точки лидара в камеру\n",
    "* Посмотрим какие точки попали в коробку\n",
    "* Оставим только эти точки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем два трансформа за одну операцию:\n",
    "* car_frame -> camera_frame,\n",
    "* camera_frame -> image_frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = intrinsic.dot(car_to_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим в однородные координаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_homogen = np.pad(xyz, ((0, 0), (0, 1)), mode='constant', constant_values=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_homogen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_homogen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь при домножении на число, новый набор координат будет продолжать задавать ту же точку в 3D-пространстве, что и до домножения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это пригодится для применения посчитанного трансформа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyw = xyz_homogen.dot(transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xyw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно вернуть на холст камеры, поделив на последнюю координату (обратное преобразование):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_cam = xyw[:, :2] / xyw[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xy_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_cam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пофильтровать по маске:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_cam_mask = (xy_cam[:, 1] < 540) * (xy_cam[:, 1] > 0) *\\\n",
    "    (xy_cam[:, 0] < 1240) * (xy_cam[:, 0] > 0) * (xyz[:, 0] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем по дальности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linalg.norm(xyz[:, :2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(image)\n",
    "plt.scatter(xy_cam[xy_cam_mask, 0], xy_cam[xy_cam_mask, 1], c=np.log1p(r[xy_cam_mask]), s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_cam = xy_cam[xy_cam_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точки внутри фрустума:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_box = (xy_cam[:, 1] > bbox[0, 0]) * (xy_cam[:, 1] < bbox[1, 0]) *\\\n",
    "    (xy_cam[:, 0] < bbox[1, 1]) * (xy_cam[:, 0] > bbox[0, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(image)\n",
    "plt.scatter(xy_cam[in_box, 0], xy_cam[in_box, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_frustum = xyz[xy_cam_mask][in_box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xyz_frustum[:, 0], xyz_frustum[:, 1], s=0.5)\n",
    "plt.xlim(0, 70)\n",
    "plt.ylim(-25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=EQUAL_ASPECT_RATIO_LAYOUT)\n",
    "fig.add_scatter3d(**{\n",
    "    'x': xyz_frustum[:,0],\n",
    "    'y': xyz_frustum[:,1],\n",
    "    'z': xyz_frustum[:,2],\n",
    "    'mode': 'markers',\n",
    "    'marker': {\n",
    "        'size': 1,\n",
    "        'color': color(intensity, 'tab20')\n",
    "    }\n",
    "})\n",
    "\n",
    "py.iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
